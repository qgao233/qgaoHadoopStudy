{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-25 14:57:48 "},"chapter1/section1/":{"url":"chapter1/section1/","title":"1 介绍","keywords":"","body":"Hadoop介绍 狭义: apache的一款开源软件,实质上是提供了一套开源框架/平台,来存储和使用大数据。 核心组件 Hadoop Distributed File System (HDFS)：分布式文件存储系统，解决海量数据存储。 Hadoop YARN ：集群资源管理和任务调试框架，解决资源任务调试。 Hadoop MapReduce：分布式计算框架，解决海量数据计算。 广义：围绕Hadoop打造的大数据生态圈。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-25 16:16:26 "},"chapter1/section2/":{"url":"chapter1/section2/","title":"2 安装与集群","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 安装 2 集群架构简介 3 部署模式 4 部署环境 4 开始部署 4.1 集群架构 4.2 统一安装工作目录（3台机器） 4.3 配置文件修改 安装与集群 1 安装 官方提供了： 源码包：供具体环境，具体编译 默认安装包：通用，但偶尔会提醒缺少环境之类的错误。 2 集群架构简介 两个集群都是标准的主从架构集群： HDFS集群（分布式存储） 主角色：NameNode(NN) 从角色：DataNode(DN) 主角色辅助角色：SecondaryNameNode(SNN) YARN集群（资源管理、调度） 主角色：ResourceManager(RM) 从角色：NodeManager(NM) 两个集群逻辑上分离、通常物理上在一起。 逻辑分离：两个集群互相之间没有依赖、互不影响。 物理一起：某些角色进程因为业务需要往往部署在同一台物理服务器上。 Hadoop集群=HDFS集群+YARN集群 没有MapReduce集群，它只是一段用于计算的代码。 3 部署模式 standalone mode：单机模式 1个机器运行1个java进程，所有角色在一个进程中运行，主要用于调试 pseudo-distributed mode：伪分布模式 1个机器支行多个进程，每个角色一个进程，主要用于调试 cluster mode：集群模式 主要用于生产环境部署，会使用N台主机组成一个Hadoop集群，主结点和从结点会分开部署在不同的机器上。 HA mode：高可用模式 在集群模式的基础上为单点故障部署备份角色，形成主备架构，实现容错性。 4 部署环境 3台机器 确认主机名hostName, 主机映射(hosts文件)：ip在前，主机名在后. 关闭防火墙：内网通信，不需要给每个端口都授予许可，直接关闭防火墙。 禁止防火墙自启 ssh免密登录：一键启动，关闭 node1->node1 node1->node2 node1->node3 集群时间同步：机器所属时区、时间都一样。 jdk安装：卸载linux自带的openJdk，安装自定义的jdk. 4 开始部署 4.1 集群架构 选择hadoop-3.1.4，搭建如下图所示的集群： https://www.bilibili.com/video/BV11N411d7Zh?p=16 4.2 统一安装工作目录（3台机器） mkdir -p /export/server #软件安装路径 mkdir -p /export/data #数据存储路径 mkdir -p /export/software #安装包存放路径 4.3 配置文件修改 hadoop-env.sh cd /export/server/hadoop-3.1.4/etc/hadoop vim hadoop-env.sh > #配置JAVA_HOME export JAVA_HOME=/export/server/jdk1.8.0_65 #设置用户以执行对应角色shell命令 export HDFS_NAMENODE_USER=root export HDFS_DATANODE_USER=root export HDFS_SECONDARYNAMENODE_USER=root export HDFS_RESOURCEMANAGER_USER=root export HDFS_NODEMANAGER_USER=root core-site.xml cd /export/server/hadoop-3.1.4/etc/hadoop/ vim core-site.xml > fs.defaultFS hdfs://node1.itcast.cn:8020 hadoop.tmp.dir /export/data/hadoop-3.1.4 hadoop.http.staticuser.user root hdfs-site.xml cd /export/server/hadoop-3.1.4/etc/hadoop vim hdfs-site.xml > dfs.namenode.secondary.http-address node2.itcast.cn:9868 mapred-site.xml(hadoop3特有错误) cd /export/server/hadoop-3.1.4/etc/hadoop vim mapred-site.xml > mapreduce.framework.name yarn yarn.app.mapreduce.am.env HADOOP_MAPRED_HOME=${HADOOP_HOME} mapreduce.map.env HADOOP_MAPRED_HOME=${HADOOP_HOME} mapreduce.reduce.env HADOOP_MAPRED_HOME=${HADOOP_HOME} yarn-site.xml(参考) cd /export/server/hadoop-3.1.4/etc/hadoop vim yarn-site.xml > yarn.resourcemanager.hostname node1.itcast.cn yarn.nodemanager.aux-services mapreduce_shuffle yarn.scheduler.minimum-allocation-mb 512 yarn.scheduler.maximum-allocation-mb 2048 yarn.nodemanager.vmem-pmem-ratio 4 workers cd /export/server/hadoop-3.1.4/etc/hadoop vim workers > node1.itcast.cn node2.itcast.cn node3.itcast.cn 分发同步安装包到其它机器（上面6步只在node1机器上更改了配置） cd /export/server scp -r hadoop-3.1.4 root@node2:/export/server scp -r hadoop-3.1.4 root@node3:/export/server 配置第4步用到的环境变量 vim /etc/profile export HADOOP_HOME=/export/server/hadoop-3.1.4 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin ##同步到其它机器 scp /etc/profile root@node2:/etc/profile scp /etc/profile root@node3:/etc/profile ##重新加载环境变量，验证是否生效（3台机器） source /etc/profile hadoop #命令行输入，验证环境变量是否生效 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-25 21:07:58 "}}