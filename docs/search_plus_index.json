{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-25 14:57:48 "},"chapter1/section1/":{"url":"chapter1/section1/","title":"1 介绍","keywords":"","body":"Hadoop介绍 狭义: apache的一款开源软件,实质上是提供了一套开源框架/平台,来存储和使用大数据。 核心组件 Hadoop Distributed File System (HDFS)：分布式文件存储系统，解决海量数据存储。 Hadoop YARN ：集群资源管理和任务调试框架，解决资源任务调试。 Hadoop MapReduce：分布式计算框架，解决海量数据计算。 广义：围绕Hadoop打造的大数据生态圈。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-25 16:16:26 "},"chapter1/section2/":{"url":"chapter1/section2/","title":"2 安装与集群","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 安装 2 集群架构简介 3 部署模式 4 部署环境 4 开始部署 4.1 集群架构 4.2 统一安装工作目录（3台机器） 4.3 配置文件修改 安装与集群 1 安装 官方提供了： 源码包：供具体环境，具体编译 默认安装包：通用，但偶尔会提醒缺少环境之类的错误。 2 集群架构简介 两个集群都是标准的主从架构集群： HDFS集群（分布式存储） 主角色：NameNode(NN) 从角色：DataNode(DN) 主角色辅助角色：SecondaryNameNode(SNN) YARN集群（资源管理、调度） 主角色：ResourceManager(RM) 从角色：NodeManager(NM) 两个集群逻辑上分离、通常物理上在一起。 逻辑分离：两个集群互相之间没有依赖、互不影响。 物理一起：某些角色进程因为业务需要往往部署在同一台物理服务器上。 Hadoop集群=HDFS集群+YARN集群 没有MapReduce集群，它只是一段用于计算的代码。 3 部署模式 standalone mode：单机模式 1个机器运行1个java进程，所有角色在一个进程中运行，主要用于调试 pseudo-distributed mode：伪分布模式 1个机器支行多个进程，每个角色一个进程，主要用于调试 cluster mode：集群模式 主要用于生产环境部署，会使用N台主机组成一个Hadoop集群，主结点和从结点会分开部署在不同的机器上。 HA mode：高可用模式 在集群模式的基础上为单点故障部署备份角色，形成主备架构，实现容错性。 4 部署环境 3台机器 确认主机名hostName, 主机映射(hosts文件)：ip在前，主机名在后. 关闭防火墙：内网通信，不需要给每个端口都授予许可，直接关闭防火墙。 禁止防火墙自启 ssh免密登录：一键启动，关闭 node1->node1 node1->node2 node1->node3 集群时间同步：机器所属时区、时间都一样。 jdk安装：卸载linux自带的openJdk，安装自定义的jdk. 4 开始部署 4.1 集群架构 选择hadoop-3.1.4，搭建如下图所示的集群： https://www.bilibili.com/video/BV11N411d7Zh?p=16 4.2 统一安装工作目录（3台机器） mkdir -p /export/server #软件安装路径 mkdir -p /export/data #数据存储路径 mkdir -p /export/software #安装包存放路径 4.3 配置文件修改 hadoop-env.sh cd /export/server/hadoop-3.1.4/etc/hadoop vim hadoop-env.sh > #配置JAVA_HOME export JAVA_HOME=/export/server/jdk1.8.0_65 #设置用户以执行对应角色shell命令 export HDFS_NAMENODE_USER=root export HDFS_DATANODE_USER=root export HDFS_SECONDARYNAMENODE_USER=root export HDFS_RESOURCEMANAGER_USER=root export HDFS_NODEMANAGER_USER=root core-site.xml cd /export/server/hadoop-3.1.4/etc/hadoop/ vim core-site.xml > fs.defaultFS hdfs://node1.itcast.cn:8020 hadoop.tmp.dir /export/data/hadoop-3.1.4 hadoop.http.staticuser.user root hdfs-site.xml cd /export/server/hadoop-3.1.4/etc/hadoop vim hdfs-site.xml > dfs.namenode.secondary.http-address node2.itcast.cn:9868 mapred-site.xml(hadoop3特有错误) cd /export/server/hadoop-3.1.4/etc/hadoop vim mapred-site.xml > mapreduce.framework.name yarn yarn.app.mapreduce.am.env HADOOP_MAPRED_HOME=${HADOOP_HOME} mapreduce.map.env HADOOP_MAPRED_HOME=${HADOOP_HOME} mapreduce.reduce.env HADOOP_MAPRED_HOME=${HADOOP_HOME} yarn-site.xml(参考) cd /export/server/hadoop-3.1.4/etc/hadoop vim yarn-site.xml > yarn.resourcemanager.hostname node1.itcast.cn yarn.nodemanager.aux-services mapreduce_shuffle yarn.scheduler.minimum-allocation-mb 512 yarn.scheduler.maximum-allocation-mb 2048 yarn.nodemanager.vmem-pmem-ratio 4 workers cd /export/server/hadoop-3.1.4/etc/hadoop vim workers > node1.itcast.cn node2.itcast.cn node3.itcast.cn 分发同步安装包到其它机器（上面6步只在node1机器上更改了配置） cd /export/server scp -r hadoop-3.1.4 root@node2:/export/server scp -r hadoop-3.1.4 root@node3:/export/server 配置第4步用到的环境变量 vim /etc/profile export HADOOP_HOME=/export/server/hadoop-3.1.4 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin ##同步到其它机器 scp /etc/profile root@node2:/etc/profile scp /etc/profile root@node3:/etc/profile ##重新加载环境变量，验证是否生效（3台机器） source /etc/profile hadoop #命令行输入，验证环境变量是否生效 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-25 21:07:58 "},"chapter1/section3/":{"url":"chapter1/section3/","title":"3 集群启动","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 NameNode format 2 启动角色 2.1 手动启动 2.2 脚本启动 2.3 启动错误 2.4 web UI 3 基准测试（benchmark） 集群启动 1 NameNode format 译为：格式化操作。 首次启动HDFS必须做的操作，本质上是初始化工作，进行HDFS清理和准备工作，如建立一些必要的工作目录和初始文件之类的。 hdfs namenode -format 敲击回车后，查看打印日志若含以下打印，则表示format成功： storage directory /export/data/hadoop-3.1.4/dfs/name has been successfully formatted. 该目录在集群环境搭建修改配置文件的第2步配置过。 该操作在启动后，不可重复执行，会造成数据丢失，导致hdfs集群主从角色互不识别。 若已经重复执行了，只有删除所有机器的hadoop.tmp.dir目录，然后重新format。 2 启动角色 角色启动完成后可以用java命令jps查看角色进程（因为这些都是java程序）。 2.1 手动启动 可以每次手动执行命令来启动或关闭一个角色进程: 精准控制某台机器的某个角色。 HDFS集群## start hdfs --daemon start namenode hdfs --daemon start datanode hdfs --daemon start secondarynamenode ## stop hdfs --daemon stop namenode hdfs --daemon stop datanode hdfs --daemon stop secondarynamenode YARN集群## start yarn --daemon start resourcemanager yarn --daemon start nodemanager ## stop yarn --daemon stop resourcemanager yarn --daemon stop nodemanager 2.2 脚本启动 sbin目录下有一键启动的脚本。 使用一键启动的脚本的前提：配置好机器之间的ssh免密登录和workers文件 hdfs集群 start-dfs.sh stop-dfs.sh yarn集群 start-yarn.sh stop-yarn.sh hadoop集群=hdfs+yarn start-all.sh stop-all.sh 2.3 启动错误 查看日志，在安装目录下的logs目录中。 2.4 web UI hdfs集群：http://namenodeHost:9870 namenodeHost: namenode所在机器的地址，即ip. windows可以通过配置hosts文件，让ip与主机名对应，使用主机名进行访问。linux不用，可直接通过主机名。 yarn集群：http://resourcemanagerHost:8088 resourcemanagerHost: resourcemanager所在机器的地址。 3 基准测试（benchmark） 又称：压力测试。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-26 11:52:34 "},"chapter2/section1/":{"url":"chapter2/section1/","title":"1 硬盘及存储架构","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 磁盘 1.1 磁盘阵列（RAID） 2 存储架构 3 文件系统 3.1 文件系统分类 4 传统存储的性能瓶颈 磁盘及存储架构 存储设备-磁盘：包括硬盘和软盘。 1 磁盘 分为： 固态盘：ssd 混合盘：sshd 机械盘：hdd 1.1 磁盘阵列（RAID） 又称为：多磁盘管理技术。 为了不同的目的有多种搭配方式。 2 存储架构 操作系统如何连接存储设备。 直连式（DAS） 网络式（NAS）：所谓的云 存储区域网络(SAN) 3 文件系统 一种存储和组织数据的方法：使得访问变得容易。 文件和树形目录（文件夹）：代替底层数据块的概念。 3.1 文件系统分类 基于磁盘的文件系统 虚拟文件系统：在内核中生成的文件系统，比如proc。 网络文件系统：通过网络访问另一台机器的文件系统。 4 传统存储的性能瓶颈 1 传统的单机存储的磁盘阵列无法支持快速扩容，缩容。 比如在数据多的时候多加几个磁盘扩容，数据少的时候拿掉几个磁盘缩容（对于普通用户来说不了解配置，无法做到快速操作）。 2 像数据多的时候，移动数据明显时间成本大，如何做到移动程序，而不移动数据。 等等。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-26 11:51:06 "},"chapter2/section2/":{"url":"chapter2/section2/","title":"2 模拟分布式文件存储","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 海量存储 2 海量数据文件查询 3 大文件传输效率 4 硬件故障->数据丢失 5 解决用户查询视角 模拟分布式文件存储 1 海量存储 解决方式： 单机纵向扩展：内存不够加内存，磁盘不够加磁盘，但有上限。 多机横向扩展（分布式）：采用多台机器存储，一台不够就加机器，理论无限。 2 海量数据文件查询 利用文件元数据：记录了文件和其对应的存储位置信息的映射。 专门用一台服务器用来存储元数据。 3 大文件传输效率 分块存储：把大文件拆分成若干小文件（block），负载均衡（分割文件平均一些）分别存储在不同机器上，并行操作提高效率。 因为分块在不同机器了，所以元数据应该记录得更详细一点：文件分为了几块，分别位于哪些机器上。 4 硬件故障->数据丢失 同一份数据，使用不同机器备份。 5 解决用户查询视角 参考windows的资源管理器的：文件夹+文件 即带有层次感的命名空间（namespace），抽象目录树结构。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-26 13:47:42 "},"chapter2/section3/":{"url":"chapter2/section3/","title":"3 hadoop分布式文件系统","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 设计目标 2 主从架构 3 分块存储 4 副本机制 5 namespace 6 元数据 7 具体存储 hadoop分布式文件系统 缩写：HDFS。 1 设计目标 硬件故障是常态 流式读取数据：被设计成用于批处理（一批次一批次的），不追求低延时的用户交互体验。 大文件 write-one-read-many访问模型：数据产生后不再用于修改，只用于分析。 移动程序优于移动数据 2 主从架构 一主多从。 namenode是主结点：命名空间，记录目录树，元数据。 datanode是从结点：真正的文件内数据。 3 分块存储 将文件从物理上真的分块(block)了。 块的大小可以通过配置，参数位于hdfs-default.xml中的dfs.blocksize，hadoop3的默认大小为128MB。 4 副本机制 文件的所有block都会有副本。 每个文件的block大小（dfs.blocksize）和副本系数（dfs.replication）都是可配置的。 副本系数默认是3，即额外复制2份，加本身一共3份。 副本系数可以在文件创建时指定，也可以之后通过命令改变。 5 namespace 层次型文件组织结构，即：文件夹+文件。 namenode主角色负责维护namespace的元数据. 6 元数据 两类： 文件自身属性信息：文件名称、权限、修改时间、大小等 文件块位置映射信息：文件和datanode之间的映射信息，即哪个块位于哪个结点上。 7 具体存储 由datanode结点承担，每一个block可在多个节点存储。 rack机架：放置机器的架子。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-26 14:23:42 "},"chapter2/section4/":{"url":"chapter2/section4/","title":"4 HDFS操作--使用shell命令","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 HDFS shell命令 1.1 dfs子命令 1.2 命令更新 2 更多命令 3 微博用户数据hdfs操作示例 HDFS操作--使用shell命令 微博HDFS案例。 1 HDFS shell命令 hdfs [options] subcommand [subcommand options] subcommand: 子命令。 1.1 dfs子命令 HDFS shell客户端支持多种文件系统，如: 本地文件系统: file:/// 自身的分布式文件系统：hdfs://nn:8020 谷歌的分布式文件系统：gfs... 等 hdfs dfs -ls file:/// #操作本地文件系统 hdfs dfs -ls hdfs://node1:8020/ #操作hdfs文件系统 hdfs dfs -ls / #根目录，因为没有指定协议，因此对应的文件系统取决于fs.defaultFS属性的值 1.2 命令更新 hadoop dfs: 过时 hdfs dfs: 常用 hadoop fs: 官方推荐 2 更多命令 hadoop fs -mkdir：新建目录 hadoop fs -ls：查看当前目录 hadoop fs -put：上传到dfs hadoop fs -copyFromLocal：上传，原本地文件被删除 hadoop fs -cat：查看文件 hadoop fs -head：查看文件首部一K的内容 hadoop fs -tail：查看文件尾部一K的内容，加上-f，可实时查看到其它进程对文件追加的内容 hadoop fs -get：下载到本地 hadoop fs -getmerge：合并成一个文件下载到本地 hadoop fs -cp：复制 hadoop fs -appendToFile：将其它文件的内容追加到目的文件的尾部，这种写方式是允许的 hadoop fs -df：查看可用空间量 hadoop fs -du：查看文件使用的空间量 hadoop fs -mv：移动 hadoop fs -setrep：修改指定文件副本个数 3 微博用户数据hdfs操作示例 目录规划 /source：用于存储原始采集数据。 /common：用于存储公共数据集，如：IP库、省份信息、经纬度等。 /workspace：工作空间，存储各团队计算出来的结果数据。 /tmp：存储临时数据，每周清理一次。 /warehouse：存储hive数据仓库中的数据。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-26 16:02:06 "},"chapter2/section5/":{"url":"chapter2/section5/","title":"5 HDFS操作--使用javaAPI","keywords":"","body":"HDFS操作--使用javaAPI 1 客户端核心类 Configuration配置对象类，用于加载或设置参数属性。 FileSystem文件系统对象基类，不同文件系统有不同具体实现，该超类封装了文件系统的相关操作方法。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-26 16:05:11 "}}